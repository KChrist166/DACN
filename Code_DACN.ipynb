{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e76e6c86-455d-47e3-b21d-caf8a3d74c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np, array\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import Sequential, layers, models, utils\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from numpy import concatenate\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64f45e3d-ab4c-4706-8055-f13e76ccf159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path:\n",
    "\n",
    "base_path = \"D:/UIT/DACN/\"\n",
    "csv_folder_path = os.path.join(base_path, \"train_csv/\")\n",
    "img_folder_path = os.path.join(base_path, \"train_img/\")\n",
    "img_path_test = \"\"\n",
    "img_path = \"\"\n",
    "\n",
    "class SequenceGenerator(Sequence):\n",
    "    def __init__(self, df, sequence_col, target_col, batch_size):\n",
    "        self.df = df\n",
    "        self.sequence_col = sequence_col\n",
    "        self.target_col = target_col\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_start = idx * self.batch_size\n",
    "        batch_end = (idx + 1) * self.batch_size\n",
    "        sequences = self.df.iloc[batch_start:batch_end][self.sequence_col].values\n",
    "        targets = self.df.iloc[batch_start:batch_end][self.target_col].values\n",
    "        return sequences, targets\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d7100c69-eda3-493a-85b8-9a85096f3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build & Train model\n",
    "\n",
    "def train_model(df, path):\n",
    "    # Split data into training and validation sets\n",
    "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_df[\"Rain (mm)\"] = train_df[\"Rain (mm)\"].astype(str)\n",
    "    val_df[\"Rain (mm)\"] = val_df[\"Rain (mm)\"].astype(str)\n",
    "    batch_size = 8\n",
    "    \n",
    "    img_gen =  ImageDataGenerator(\n",
    "        rescale=1 / 255.0,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.05,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",)\n",
    "    \n",
    "    train_generator = img_gen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=path,\n",
    "        x_col=\"IMG_Path\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "\n",
    "    valid_generator = img_gen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=path,\n",
    "        x_col=\"IMG_Path\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        subset='validation',\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "    \n",
    "    seq_gen = SequenceGenerator(train_df, 'Sequences', 'Rain (mm)', batch_size=batch_size)\n",
    "    seq_embedding = Embedding(input_dim=100, output_dim=128, input_length=10)\n",
    "    \n",
    "    # Define CNN model\n",
    "    img_input = Input(shape=(224, 224, 3))\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(img_input)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    img_output = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Define sequence input\n",
    "    seq_input = Input(shape=(3,))\n",
    "    seq_embedding_output = seq_embedding(seq_input)\n",
    "    \n",
    "    # Concatenate CNN and sequence inputs\n",
    "    concat_input = concatenate([img_output, seq_embedding_output])\n",
    "    # define LSTM layer\n",
    "    lstm_output = LSTM(128)(concat_input)\n",
    "    # Define output layer\n",
    "    output = Dense(1)(lstm_output)\n",
    "\n",
    "    # Define model\n",
    "    model = Model(inputs=[img_input, seq_input], outputs=output)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    model.fit(x = [train_generator, seq_gen],\n",
    "              validation_data = [valid_generator, seq_gen],\n",
    "              steps_per_epoch = train_generator.n//train_generator.batch_size,\n",
    "              validation_steps = valid_generator.n//valid_generator.batch_size,\n",
    "              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14f3a62a-a3f8-4983-93b0-080c5fc01fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function:\n",
    "\n",
    "def get_csv_file_name(file_path):\n",
    "    csv_file = os.path.basename(file_path)\n",
    "    csv_name = csv_file[:-4]\n",
    "    return csv_name\n",
    "\n",
    "def find_img_folder_matched(csv_name):\n",
    "    for img_folder in os.listdir(img_folder_path):\n",
    "        full_img_folder_path = os.path.join(img_folder_path, img_folder)   \n",
    "        if os.path.isdir(full_img_folder_path) and img_folder == csv_name:\n",
    "            matching_img_folder = full_img_folder_path\n",
    "            break\n",
    "    return matching_img_folder\n",
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    # Perform any additional preprocessing steps as needed (e.g., normalization)\n",
    "    return np.array(image)  # Convert PIL image to numpy array\n",
    "\n",
    "def preprocess_sequence(sequence):\n",
    "    # Perform any preprocessing steps (e.g., normalization)\n",
    "    return np.array(sequence)\n",
    "\n",
    "def prepare_data_to_train(file, path, file_count, csv_file_paths):\n",
    "    label_file_path = os.path.join(path, file)             # file csv được chọn ban đầu đặt làm file target (đường dẫn)\n",
    "    target_file_path = csv_file_paths[file_count - 1]\n",
    "    target_file_name = get_csv_file_name(target_file_path)  # từ đường dẫn file target -> tên file (time file)\n",
    "    img_folder_matched = find_img_folder_matched(target_file_name)  # từ tên file (time file) -> folder chứa ảnh tương ứng\n",
    "    \n",
    "    # Đọc file CSV và chỉ đọc các cột được chỉ định vào DataFrame\n",
    "    columns_to_read = [\"City\", \"Rain (mm)\"]                      \n",
    "    df = pd.read_csv(label_file_path, usecols=columns_to_read)\n",
    "    \n",
    "    num_row = df.shape[0]\n",
    "    sequences = np.empty((num_row, 3))\n",
    "    for i in range(3):  # Vòng lặp từ i=0 đến i=2\n",
    "        # Đọc file CSV\n",
    "        file_index = file_count + i - 3 \n",
    "        new_df = pd.read_csv(csv_file_paths[file_index])\n",
    "        # Gán giá trị vào cột i của ma trận sequences\n",
    "        sequences[:, i] = new_df[\"Rain (mm)\"]\n",
    "\n",
    "    # Tạo DataFrame từ ma trận sequences với tên cột là \"Sequences\"\n",
    "    sequences_df = pd.DataFrame(sequences)\n",
    "    sequences_df[\"Sequences\"] = sequences_df.apply(lambda row: row.tolist(), axis=1)\n",
    "\n",
    "    df.rename(columns={\"City\": \"IMG_Path\"}, inplace=True)\n",
    "    # Áp dụng hàm lambda vào cột \"IMG_Path\"\n",
    "    df[\"IMG_Path\"] = df[\"IMG_Path\"].apply(lambda city_name: os.path.join(img_folder_matched, f\"{city_name}.png\"))\n",
    "    \n",
    "    # Ghép DataFrame sequences_df vào giữa 2 cột của DataFrame df\n",
    "    df = pd.concat([df.iloc[:, :1], sequences_df, df.iloc[:, 1:]], axis=1)\n",
    "    pd.set_option(\"display.max_colwidth\", None)\n",
    "    # df.rename(columns={\"Rain (mm)\": \"Rain_mm\"}, inplace=True)\n",
    "    \n",
    "    global img_path\n",
    "    img_path = img_folder_matched\n",
    "    \n",
    "    return df.drop(columns=df.columns[1:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0779aaca-94c7-4ef3-97b5-8540c8dd193d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     14\u001b[0m     df \u001b[38;5;241m=\u001b[39m prepare_data_to_train(csv_file, csv_folder_path, file_count, csv_file_paths)\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# df.to_csv(output_csv_path, index=False)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# print(df.to_string(index=False))\u001b[39;00m\n\u001b[0;32m     18\u001b[0m file_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[77], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(df, path)\u001b[0m\n\u001b[0;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m     10\u001b[0m img_gen \u001b[38;5;241m=\u001b[39m  ImageDataGenerator(\n\u001b[0;32m     11\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m,\n\u001b[0;32m     12\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m     fill_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m---> 20\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mimg_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIMG_Path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m valid_generator \u001b[38;5;241m=\u001b[39m img_gen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(\n\u001b[0;32m     32\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mtrain_df,\n\u001b[0;32m     33\u001b[0m     directory\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     40\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     42\u001b[0m seq_gen \u001b[38;5;241m=\u001b[39m SequenceGenerator(train_df, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSequences\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRain (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:1807\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m   1801\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1802\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1803\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1804\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1805\u001b[0m     )\n\u001b[1;32m-> 1807\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1825\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1826\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_filenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1829\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:968\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m    967\u001b[0m \u001b[38;5;66;03m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    970\u001b[0m     validate_filenames\n\u001b[0;32m    971\u001b[0m ):  \u001b[38;5;66;03m# check which image files are valid and keep them\u001b[39;00m\n\u001b[0;32m    972\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\preprocessing\\image.py:1057\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[1;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1056\u001b[0m     types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, types))):\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf class_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, y_col=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m column \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1060\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues must be type string, list or tuple.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1061\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode, y_col\n\u001b[0;32m   1062\u001b[0m             )\n\u001b[0;32m   1063\u001b[0m         )\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# raise warning if classes are given but will be unused\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "# Train:\n",
    "\n",
    "csv_file_paths = []\n",
    "file_count = 0\n",
    "df=pd.DataFrame()\n",
    "\n",
    "\n",
    "for csv_file in os.listdir(csv_folder_path):\n",
    "    if csv_file.endswith(\".csv\"):\n",
    "        csv_paths = os.path.join(csv_folder_path, csv_file)\n",
    "        csv_file_paths.append(csv_paths)   \n",
    "\n",
    "        if file_count >= 3:\n",
    "            df = prepare_data_to_train(csv_file, csv_folder_path, file_count, csv_file_paths)\n",
    "            train_model(df, img_path)\n",
    "            # df.to_csv(output_csv_path, index=False)\n",
    "            # print(df.to_string(index=False))\n",
    "        file_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e8187a8c-ef8e-4953-8be5-87965a672ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 validated image filenames belonging to 2 classes.\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4479 - accuracy: 1.0000\n",
      "\n",
      "Test loss: 0.44794896245002747\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "csv_test_path = \"D:/UIT/DACN/test_csv/2024-01-15-11-02-05.csv\"\n",
    "columns_to_keep = [\"City\", \"Rain (mm)\"]\n",
    "test_df = pd.read_csv(csv_test_path, usecols=columns_to_keep)\n",
    "test_df['City'] = test_df['City'].apply(lambda x: x + '.png')\n",
    "test_df['Rain (mm)'] = test_df['Rain (mm)'].astype(str)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1 / 255.0,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.05,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        validation_split=0.20)\n",
    "\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=img_path_test,\n",
    "        x_col=\"City\",\n",
    "        y_col=\"Rain (mm)\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=8,\n",
    "        class_mode=\"categorical\",\n",
    "        subset='validation',\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "\n",
    "score = model.evaluate(valid_generator)\n",
    "print('\\nTest loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d7c4b00-55b9-4562-b7b0-be2d009537f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 validated image filenames.\n",
      "76/76 [==============================] - 1s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict:\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1 / 255.0,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.05,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.05,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\",\n",
    "        validation_split=0.20)        \n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=img_path_test,\n",
    "    x_col=\"City\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False,)\n",
    "\n",
    "predict = model.predict(test_generator, steps=len(test_generator.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eaa63857-b9f1-4f2d-a924-e01fe43f9203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "result_predict = predict.argmax(axis=-1)\n",
    "print(result_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f44ab51-b03a-4255-ad17-ff09d669a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "real_result = np.array(test_df['Rain (mm)'].astype(int))\n",
    "print(np.array_str(real_result, precision=0, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1dded06-866c-439b-a4fb-31aecfe92f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99        75\n",
      "           1       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.99        76\n",
      "   macro avg       0.99      0.50      0.50        76\n",
      "weighted avg       0.99      0.99      0.98        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "\n",
    "labels = test_df['Rain (mm)'].astype(int).tolist()\n",
    "\n",
    "predicted_labels = np.argmax(predict, axis=1)\n",
    "\n",
    "print(classification_report(labels, predicted_labels, zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
